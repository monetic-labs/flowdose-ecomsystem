name: Deploy to DigitalOcean Droplets

on:
  push:
    branches:
      - master
    paths:
      - 'backend/**'
      - 'storefront/**'
      - '.github/workflows/do-droplet-deploy.yml'
      - 'deploy-trigger'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging

jobs:
  prepare_deployment:
    name: Prepare Deployment
    runs-on: ubuntu-latest
    outputs:
      backend_ip: ${{ steps.get_ips.outputs.backend_ip }}
      storefront_ip: ${{ steps.get_ips.outputs.storefront_ip }}
      can_deploy: ${{ steps.get_ips.outputs.can_deploy }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0
        
      - name: Set Terraform Provider Credentials
        run: |
          # Instead of creating a new provider file, update the existing one
          sed -i 's/token = var.do_token/token = "${{ secrets.DO_API_TOKEN }}"/g' terraform/main.tf
        
      - name: Create Docker Compose Files
        run: |
          # Ensure deploy directory exists
          mkdir -p deploy
          
          # Create backend compose file if it doesn't exist
          if [ ! -f "deploy/backend-compose.yml" ]; then
            cat > deploy/backend-compose.yml << 'EOL'
          version: '3.8'
          services:
            backend:
              build:
                context: ../backend
                dockerfile: Dockerfile
              environment:
                - NODE_ENV=${ENVIRONMENT}
                - DATABASE_URL=${DATABASE_URL}
                - REDIS_URL=${REDIS_URL}
                - PORT=9000
                # CORS settings
                - ADMIN_CORS=https://${ADMIN_DOMAIN},https://${STORE_DOMAIN}
                - STORE_CORS=https://${STORE_DOMAIN}
                - AUTH_CORS=https://${ADMIN_DOMAIN},https://${STORE_DOMAIN}
                # Auth secrets
                - JWT_SECRET=${JWT_SECRET}
                - COOKIE_SECRET=${COOKIE_SECRET}
                # Admin account
                - MEDUSA_ADMIN_EMAIL=${ADMIN_EMAIL}
                - MEDUSA_ADMIN_PASSWORD=${ADMIN_PASSWORD}
                # Publishable Key
                - MEDUSA_PUBLISHABLE_KEY=${PUBLISHABLE_KEY}
              restart: always
              networks:
                - flowdose-network

            caddy:
              image: caddy:2-alpine
              restart: unless-stopped
              ports:
                - "80:80"
                - "443:443"
              volumes:
                - ./Caddyfile_backend:/etc/caddy/Caddyfile
                - ../data/caddy_data:/data
                - ../data/caddy_config:/config
              depends_on:
                - backend
              networks:
                - flowdose-network

          networks:
            flowdose-network:
              external: true
          EOL
          fi
          
          # Create storefront compose file if it doesn't exist
          if [ ! -f "deploy/storefront-compose.yml" ]; then
            cat > deploy/storefront-compose.yml << 'EOL'
          version: '3.8'
          services:
            storefront:
              build:
                context: ../storefront
                dockerfile: Dockerfile
                args:
                  - NEXT_PUBLIC_MEDUSA_BACKEND_URL=https://${ADMIN_DOMAIN}
                  - NEXT_PUBLIC_MEDUSA_PUBLISHABLE_KEY=${PUBLISHABLE_KEY}
                  - NEXT_PUBLIC_BASE_URL=https://${STORE_DOMAIN}
              environment:
                - NODE_ENV=${ENVIRONMENT}
                - NEXT_PUBLIC_MEDUSA_BACKEND_URL=https://${ADMIN_DOMAIN}
                - NEXT_PUBLIC_MEDUSA_PUBLISHABLE_KEY=${PUBLISHABLE_KEY}
                - NEXT_PUBLIC_BASE_URL=https://${STORE_DOMAIN}
                - PORT=3000
              restart: always
              networks:
                - flowdose-network

            caddy:
              image: caddy:2-alpine
              restart: unless-stopped
              ports:
                - "80:80"
                - "443:443"
              volumes:
                - ./Caddyfile_storefront:/etc/caddy/Caddyfile
                - ../data/caddy_data:/data
                - ../data/caddy_config:/config
              depends_on:
                - storefront
              networks:
                - flowdose-network

          networks:
            flowdose-network:
              external: true
          EOL
          fi
        
      - name: Get Server IPs from Terraform Output
        id: get_ips
        working-directory: terraform
        env:
          TF_VAR_do_token: ${{ secrets.DO_API_TOKEN }}
          DO_SPACES_ACCESS_KEY: ${{ secrets.DO_SPACES_ACCESS_KEY }}
          DO_SPACES_SECRET_KEY: ${{ secrets.DO_SPACES_SECRET_KEY }}
          # Fallback IPs if Terraform state is inaccessible
          FALLBACK_BACKEND_IP: ${{ vars.BACKEND_IP || '127.0.0.1' }}
          FALLBACK_STOREFRONT_IP: ${{ vars.STOREFRONT_IP || '127.0.0.1' }}
        run: |
          # Check if secrets exist
          if [ -z "$DO_SPACES_ACCESS_KEY" ] || [ -z "$DO_SPACES_SECRET_KEY" ]; then
            echo "WARNING: DigitalOcean Spaces credentials are missing!"
            echo "Will attempt to use fallback IPs from repository variables."
            
            if [ "$FALLBACK_BACKEND_IP" = "127.0.0.1" ] || [ "$FALLBACK_STOREFRONT_IP" = "127.0.0.1" ]; then
              echo "ERROR: No fallback IPs configured. Set BACKEND_IP and STOREFRONT_IP variables in the repository."
              echo "can_deploy=false" >> $GITHUB_OUTPUT
              exit 1
            fi
            
            echo "backend_ip=$FALLBACK_BACKEND_IP" >> $GITHUB_OUTPUT
            echo "storefront_ip=$FALLBACK_STOREFRONT_IP" >> $GITHUB_OUTPUT
            echo "can_deploy=true" >> $GITHUB_OUTPUT
            
            echo "Using Fallback Backend IP: $FALLBACK_BACKEND_IP"
            echo "Using Fallback Storefront IP: $FALLBACK_STOREFRONT_IP"
            exit 0
          fi
          
          # Initialize Terraform with backend credentials
          terraform init -backend-config="access_key=$DO_SPACES_ACCESS_KEY" \
                         -backend-config="secret_key=$DO_SPACES_SECRET_KEY" \
                         -reconfigure
          
          # Get output values from Terraform state
          BACKEND_IP=$(terraform output -raw backend_ip 2>/dev/null || echo "")
          STOREFRONT_IP=$(terraform output -raw storefront_ip 2>/dev/null || echo "")
          
          # Check if both IPs exist
          if [ -z "$BACKEND_IP" ] || [ -z "$STOREFRONT_IP" ]; then
            echo "Infrastructure not fully provisioned yet."
            
            # Use fallback IPs
            if [ "$FALLBACK_BACKEND_IP" = "127.0.0.1" ] || [ "$FALLBACK_STOREFRONT_IP" = "127.0.0.1" ]; then
              echo "No fallback IPs configured either. Deployment cannot proceed."
              echo "can_deploy=false" >> $GITHUB_OUTPUT
              exit 1
            else
              echo "Using fallback IPs from repository variables."
              BACKEND_IP=$FALLBACK_BACKEND_IP
              STOREFRONT_IP=$FALLBACK_STOREFRONT_IP
            fi
          fi
          
          # Output these values for other jobs
          echo "backend_ip=$BACKEND_IP" >> $GITHUB_OUTPUT
          echo "storefront_ip=$STOREFRONT_IP" >> $GITHUB_OUTPUT
          echo "can_deploy=true" >> $GITHUB_OUTPUT
          
          echo "Using Backend IP: $BACKEND_IP"
          echo "Using Storefront IP: $STOREFRONT_IP"

  build_backend:
    name: Build Backend
    needs: prepare_deployment
    if: needs.prepare_deployment.outputs.can_deploy == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Cache Docker layers
        uses: actions/cache@v3
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-backend-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-backend-
      
      - name: Build Backend Image
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: false
          load: true
          tags: flowdose-backend:latest
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new
      
      - name: Save Backend Image
        run: |
          mkdir -p /tmp/docker-images
          docker save flowdose-backend:latest | gzip > /tmp/docker-images/backend.tar.gz
      
      - name: Upload Backend Image
        uses: actions/upload-artifact@v4
        with:
          name: backend-image
          path: /tmp/docker-images/backend.tar.gz
          retention-days: 1
      
      # Prevent cache from growing too large
      - name: Move cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache

  build_storefront:
    name: Build Storefront
    needs: prepare_deployment
    if: needs.prepare_deployment.outputs.can_deploy == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Cache Docker layers
        uses: actions/cache@v3
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-storefront-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-storefront-
      
      - name: Build Storefront Image
        uses: docker/build-push-action@v5
        with:
          context: ./storefront
          push: false
          load: true
          tags: flowdose-storefront:latest
          build-args: |
            NEXT_PUBLIC_MEDUSA_BACKEND_URL=${{ secrets.DOMAIN_NAME && format('https://admin.{0}', secrets.DOMAIN_NAME) || format('http://{0}:9000', needs.prepare_deployment.outputs.backend_ip) }}
            NEXT_PUBLIC_MEDUSA_PUBLISHABLE_KEY=${{ secrets.PUBLISHABLE_KEY }}
            NEXT_PUBLIC_BASE_URL=${{ secrets.DOMAIN_NAME && format('https://store.{0}', secrets.DOMAIN_NAME) || format('http://{0}:3000', needs.prepare_deployment.outputs.storefront_ip) }}
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new
      
      - name: Save Storefront Image
        run: |
          mkdir -p /tmp/docker-images
          docker save flowdose-storefront:latest | gzip > /tmp/docker-images/storefront.tar.gz
      
      - name: Upload Storefront Image
        uses: actions/upload-artifact@v4
        with:
          name: storefront-image
          path: /tmp/docker-images/storefront.tar.gz
          retention-days: 1
      
      # Prevent cache from growing too large
      - name: Move cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache

  deploy_backend:
    name: Deploy Backend
    needs: [prepare_deployment, build_backend]
    runs-on: ubuntu-latest
    env:
      DEPLOY_ENV: ${{ github.event.inputs.environment || 'production' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Download Backend Image
        uses: actions/download-artifact@v4
        with:
          name: backend-image
          path: /tmp/docker-images
      
      - name: Install SSH Key
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.DO_SSH_PRIVATE_KEY }}
          known_hosts: 'just-a-placeholder'
      
      - name: Add Known Hosts
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -H ${{ needs.prepare_deployment.outputs.backend_ip }} >> ~/.ssh/known_hosts
      
      - name: Create Caddy Config
        run: |
          mkdir -p deploy
          
          # Create Caddyfile for backend
          cat > deploy/Caddyfile_backend << EOF
          ${{ secrets.DOMAIN_NAME && format('admin.{0}', secrets.DOMAIN_NAME) || format('{0}:80', needs.prepare_deployment.outputs.backend_ip) }} {
              reverse_proxy backend:9000
              ${{ secrets.DOMAIN_NAME && 'tls ' }}${{ secrets.DOMAIN_NAME && (secrets.ADMIN_EMAIL || 'admin@flowdose.xyz') }}
          }
          EOF
      
      - name: Create Docker Compose
        run: |
          cat > deploy/docker-compose.yml << EOF
          version: '3.8'
          services:
            backend:
              image: flowdose-backend:latest
              environment:
                NODE_ENV: ${{ env.DEPLOY_ENV }}
                DATABASE_URL: ${{ secrets.DATABASE_URL }}
                REDIS_URL: ${{ secrets.REDIS_URL }}
                PORT: 9000
                ADMIN_CORS: ${{ secrets.DOMAIN_NAME && format('https://admin.{0},https://store.{0}', secrets.DOMAIN_NAME) || format('http://{0}:9000,http://{1}:3000', needs.prepare_deployment.outputs.backend_ip, needs.prepare_deployment.outputs.storefront_ip) }}
                STORE_CORS: ${{ secrets.DOMAIN_NAME && format('https://store.{0}', secrets.DOMAIN_NAME) || format('http://{0}:3000', needs.prepare_deployment.outputs.storefront_ip) }}
                AUTH_CORS: ${{ secrets.DOMAIN_NAME && format('https://admin.{0},https://store.{0}', secrets.DOMAIN_NAME) || format('http://{0}:9000,http://{1}:3000', needs.prepare_deployment.outputs.backend_ip, needs.prepare_deployment.outputs.storefront_ip) }}
                JWT_SECRET: ${{ secrets.JWT_SECRET }}
                COOKIE_SECRET: ${{ secrets.COOKIE_SECRET }}
                MEDUSA_ADMIN_EMAIL: admin@flowdose.xyz
                MEDUSA_ADMIN_PASSWORD: ${{ secrets.ADMIN_PASSWORD }}
                MEDUSA_PUBLISHABLE_KEY: ${{ secrets.PUBLISHABLE_KEY }}
                PUBLISHABLE_KEY: ${{ secrets.PUBLISHABLE_KEY }}
                PGSSLROOTCERT: /app/certs/do-ca-certificate.crt
                PGSSLMODE: verify-ca
              restart: always
              networks:
                - flowdose-network

            caddy:
              image: caddy:2-alpine
              restart: unless-stopped
              ports:
                - "80:80"
                - "443:443"
              volumes:
                - ./Caddyfile_backend:/etc/caddy/Caddyfile
                - ./data/caddy_data:/data
                - ./data/caddy_config:/config
              depends_on:
                - backend
              networks:
                - flowdose-network

          networks:
            flowdose-network:
              name: flowdose-network
              external: true
          EOF
      
      - name: Deploy to Server
        run: |
          # Ensure proper directories exist
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.backend_ip }} "
            mkdir -p /opt/flowdose/data/caddy_data /opt/flowdose/data/caddy_config
          "
          
          # Transfer Docker image and configs
          scp -o StrictHostKeyChecking=no /tmp/docker-images/backend.tar.gz root@${{ needs.prepare_deployment.outputs.backend_ip }}:/opt/flowdose/
          scp -o StrictHostKeyChecking=no deploy/Caddyfile_backend root@${{ needs.prepare_deployment.outputs.backend_ip }}:/opt/flowdose/
          scp -o StrictHostKeyChecking=no deploy/docker-compose.yml root@${{ needs.prepare_deployment.outputs.backend_ip }}:/opt/flowdose/
          
          # Load image and start services
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.backend_ip }} "
            cd /opt/flowdose && 
            # Create network if it doesn't exist
            docker network create flowdose-network || true
            # Load the Docker image
            docker load < backend.tar.gz &&
            # Stop any running containers
            docker compose down || true &&
            # Start services
            docker compose up -d
          "

  deploy_storefront:
    name: Deploy Storefront
    needs: [prepare_deployment, build_storefront]
    runs-on: ubuntu-latest
    env:
      DEPLOY_ENV: ${{ github.event.inputs.environment || 'production' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Download Storefront Image
        uses: actions/download-artifact@v4
        with:
          name: storefront-image
          path: /tmp/docker-images
      
      - name: Install SSH Key
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.DO_SSH_PRIVATE_KEY }}
          known_hosts: 'just-a-placeholder'
      
      - name: Add Known Hosts
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -H ${{ needs.prepare_deployment.outputs.storefront_ip }} >> ~/.ssh/known_hosts
      
      - name: Create Caddy Config
        run: |
          mkdir -p deploy
          
          # Create Caddyfile for storefront
          cat > deploy/Caddyfile_storefront << EOF
          ${{ secrets.DOMAIN_NAME && format('store.{0}', secrets.DOMAIN_NAME) || format('{0}:80', needs.prepare_deployment.outputs.storefront_ip) }} {
              reverse_proxy storefront:3000
              ${{ secrets.DOMAIN_NAME && 'tls ' }}${{ secrets.DOMAIN_NAME && (secrets.ADMIN_EMAIL || 'admin@flowdose.xyz') }}
          }
          EOF
      
      - name: Create Docker Compose
        run: |
          cat > deploy/docker-compose.yml << EOF
          version: '3.8'
          services:
            storefront:
              image: flowdose-storefront:latest
              environment:
                NODE_ENV: ${{ env.DEPLOY_ENV }}
                NEXT_PUBLIC_MEDUSA_BACKEND_URL: ${{ secrets.DOMAIN_NAME && format('https://admin.{0}', secrets.DOMAIN_NAME) || format('http://{0}:9000', needs.prepare_deployment.outputs.backend_ip) }}
                NEXT_PUBLIC_MEDUSA_PUBLISHABLE_KEY: ${{ secrets.PUBLISHABLE_KEY }}
                PUBLISHABLE_KEY: ${{ secrets.PUBLISHABLE_KEY }}
                NEXT_PUBLIC_BASE_URL: ${{ secrets.DOMAIN_NAME && format('https://store.{0}', secrets.DOMAIN_NAME) || format('http://{0}:3000', needs.prepare_deployment.outputs.storefront_ip) }}
                PORT: 3000
              restart: always
              networks:
                - flowdose-network

            caddy:
              image: caddy:2-alpine
              restart: unless-stopped
              ports:
                - "80:80"
                - "443:443"
              volumes:
                - ./Caddyfile_storefront:/etc/caddy/Caddyfile
                - ./data/caddy_data:/data
                - ./data/caddy_config:/config
              depends_on:
                - storefront
              networks:
                - flowdose-network

          networks:
            flowdose-network:
              name: flowdose-network
              external: true
          EOF
      
      - name: Deploy to Server
        run: |
          # Ensure proper directories exist
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.storefront_ip }} "
            mkdir -p /opt/flowdose/data/caddy_data /opt/flowdose/data/caddy_config
          "
          
          # Transfer Docker image and configs
          scp -o StrictHostKeyChecking=no /tmp/docker-images/storefront.tar.gz root@${{ needs.prepare_deployment.outputs.storefront_ip }}:/opt/flowdose/
          scp -o StrictHostKeyChecking=no deploy/Caddyfile_storefront root@${{ needs.prepare_deployment.outputs.storefront_ip }}:/opt/flowdose/
          scp -o StrictHostKeyChecking=no deploy/docker-compose.yml root@${{ needs.prepare_deployment.outputs.storefront_ip }}:/opt/flowdose/
          
          # Load image and start services
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.storefront_ip }} "
            cd /opt/flowdose && 
            # Create network if it doesn't exist
            docker network create flowdose-network || true
            # Load the Docker image
            docker load < storefront.tar.gz &&
            # Stop any running containers
            docker compose down || true &&
            # Start services
            docker compose up -d
          " 